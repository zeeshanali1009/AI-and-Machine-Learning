Artifical Intelligence:
    1. ANI (Artificial Narrow Intelligence)
        like smart speakers, self driving cars, web search, AI in farming and factories.
    2. AGI (Artificial General Intelligence)
        do anything that human can do.

 Artifical Intelligence
 It is the branch of computer science concerned with development of methods that allows computer to learn without explicit programming.
 Search algorithms, rule based system, ststistical inference, machine learning.
    Machine Learning
    It is the branch of artificial intelligence that can learn from examples and experience instead of relying on hard-coded rules and make predictions on new data.
    svm, tree algorithms, nearest neighbors, bagging, boosting, deep learning.
        Deep Learning
        It is the subfield of machine learning that focuses on neural networks (inspired from biological neurons) to deveelop learning models.
        fcns, cnns, rnns, transformers, autoencoders, gans
------------------------------------------------------------------------------------------------------------------------------------------------------------
Samples and datapoints are the same terminologies.
Neuron:
Neuron is the most fundamntal part of the deep learning which contains the three basic things: input interconnections and the output.
Neuron is basically a function that performs a specific function.
Neurons need great:
data
computational power
well trained algorithms

Artificial intelligence is distributed into two parts
1. Descriminative (Creates the patterns, descriminate the data, make the seperations, involes the conventional models that deals with structured data better)
    1. Supervised Learning
    2. Unsupervised learning
    3. Reinforcement learning
2. Generative (generates the information can deal with both structured and unstructured data as well)
    1. NLP(Natural Language Processing)
        It deals with the natural language with the text and with the neurons that deals with this sort of data.
    2. Speech Recognition
        It deals with the speech,voice related data.
    3. Computer Vision
        it deals with the images, videoes.

Generative AI Models:
1. LLM
    LLMs are the generative pretrained transformers that are too large such as chatgpt 3 had 176 billion parameters/neurons.
    Tokenization is the most important concept in the NLP which is the process of breaking down the tecxt into the smaller units called the tokens. which 
    can be words, phrases even the chracters. like it is the vocabulary of the models. token can be single chracter, word or the sentence.
    like: This is the first step in NLP has the tokens t h i s i s t h e f i r s t .........
    context window: it is the limit of the model to accept , process, the tokens like gpt has the 4k and so on etc.
2. Latent Diffusion Models
    Diffusion means going from high intensity towards the lower intensity (In generic) like the ink drop being fallen on the shirt and then starts to spread slowly.
    Stable diffusion
    Latent diffusion model (latent means hidden)
    Actually when we say that the picture is 1024 x 1024 it means that there are many pixels in it (like in millions) one individual pixel has three colors rgb so there is too much 
    computation required for the images in the ai field then for the minimization of the computation we use the latent vectors behind that reduces the computation power to 48 times.
    hence the model is called the diffusion model.
   
    Actually the noise is being added into the picture unite time after unit time and then the noise is also removed unit time after the unit time and this complete process is systematic.
    noise is added                                      noise is removed 
    forward stable diffusion                            reverse stable diffusion
    conversion of pixels into the embeddings            conversion of the embeddings to the pixels
    Encoding                                            Decoding




Text Generation
    chatgpt 3.5/4, bard
Image Generation
    Dalle-E3, Stable diffusion
Music Generation
    Music-LM
Video Generation
    Runway ML, Gen-2

Prompt Engineering:
A prompt refers to the input or instructions provided to the model to generate a specific response or output.
Anatomy of Prompt Engineering
1. Simulate Persona 
2. Taks
3. Steps to complete Tasks
4. Context/Constraints
5. Goal
6. Format Output

Tips for Effective Prompt Engineering:
be explicit: clearly specify the desired format or output.
provide context: offer relevant information or background to guide the model.
control output length: instruct the model to generate responses of a specific length.
restrict responses: utilize techniques like temperature adjustments to refine output quality.
experiment and iterate: refine prompts through experimentation and feedback loops.

Servers important parts:
hard disk 
ram
processer
network 
these factors decide the performance of the server being in use.

API (Application programming interface)
API acts as an intermediate or we can say the medium between two channels for the effective communication.
like we use the open ai  api keys for the differnent type of models execution like for the LLM related models.
API keys are very sensitive. It is very important to keep them in secret. we keep them in the secret for saving
ourself from the execessive cost expenditures.
